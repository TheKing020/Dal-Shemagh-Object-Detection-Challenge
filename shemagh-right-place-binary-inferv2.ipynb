{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5e6be0",
   "metadata": {
    "_cell_guid": "52793e1b-136a-4166-837c-c1d24ed308c1",
    "_uuid": "e0373a93-6d00-4fb4-8295-e6a16c9a2f98",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-02-16T02:17:03.091776Z",
     "iopub.status.busy": "2026-02-16T02:17:03.091470Z",
     "iopub.status.idle": "2026-02-16T02:18:00.692900Z",
     "shell.execute_reply": "2026-02-16T02:18:00.691890Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 57.607781,
     "end_time": "2026-02-16T02:18:00.694876",
     "exception": false,
     "start_time": "2026-02-16T02:17:03.087095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Found 842 images\n",
      "\n",
      "Inference Options:\n",
      "1. Ensemble (All folds) - Most accurate\n",
      "2. Best single model - Faster\n",
      "3. Ensemble with TTA - Highest accuracy (slower)\n",
      "\n",
      "ðŸš€ Running Ensemble Prediction (All Folds)...\n",
      "\n",
      "============================================================\n",
      "Loading Fold 1 weights...\n",
      "============================================================\n",
      "âœ“ Model loaded successfully\n",
      "  - Epoch: 3\n",
      "  - Val AUC: 0.8414\n",
      "  - Val Acc: 0.6946\n",
      "  - Val F1: 0.5854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:10<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Loading Fold 2 weights...\n",
      "============================================================\n",
      "âœ“ Model loaded successfully\n",
      "  - Epoch: 6\n",
      "  - Val AUC: 0.8816\n",
      "  - Val Acc: 0.7725\n",
      "  - Val F1: 0.6607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:04<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Loading Fold 3 weights...\n",
      "============================================================\n",
      "âœ“ Model loaded successfully\n",
      "  - Epoch: 12\n",
      "  - Val AUC: 0.8604\n",
      "  - Val Acc: 0.8084\n",
      "  - Val F1: 0.6863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:04<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Loading Fold 4 weights...\n",
      "============================================================\n",
      "âœ“ Model loaded successfully\n",
      "  - Epoch: 5\n",
      "  - Val AUC: 0.8876\n",
      "  - Val Acc: 0.7771\n",
      "  - Val F1: 0.6542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:04<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Loading Fold 5 weights...\n",
      "============================================================\n",
      "âœ“ Model loaded successfully\n",
      "  - Epoch: 4\n",
      "  - Val AUC: 0.7998\n",
      "  - Val Acc: 0.6807\n",
      "  - Val F1: 0.5760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:04<00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ENSEMBLE SUMMARY\n",
      "============================================================\n",
      "Models used: 5/5\n",
      "  Fold 1: AUC=0.8414, Acc=0.6946\n",
      "  Fold 2: AUC=0.8816, Acc=0.7725\n",
      "  Fold 3: AUC=0.8604, Acc=0.8084\n",
      "  Fold 4: AUC=0.8876, Acc=0.7771\n",
      "  Fold 5: AUC=0.7998, Acc=0.6807\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "PREDICTION SUMMARY\n",
      "============================================================\n",
      "Total images: 842\n",
      "\n",
      "Class distribution:\n",
      "prediction_class\n",
      "0    625\n",
      "1    217\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Confidence statistics:\n",
      "count    842.000000\n",
      "mean       0.698573\n",
      "std        0.084724\n",
      "min        0.500010\n",
      "25%        0.638446\n",
      "50%        0.708972\n",
      "75%        0.767214\n",
      "max        0.876097\n",
      "Name: confidence, dtype: float64\n",
      "\n",
      "============================================================\n",
      "Top 10 Most Confident Predictions:\n",
      "============================================================\n",
      "filename  prediction_class  prediction_prob  confidence\n",
      "  41.jpg                 1         0.876097    0.876097\n",
      " 319.jpg                 1         0.867351    0.867351\n",
      " 693.jpg                 1         0.864327    0.864327\n",
      " 712.jpg                 1         0.861979    0.861979\n",
      " 117.jpg                 1         0.855168    0.855168\n",
      " 267.jpg                 1         0.853722    0.853722\n",
      " 558.jpg                 1         0.848945    0.848945\n",
      " 535.jpg                 1         0.847706    0.847706\n",
      " 227.jpg                 1         0.843948    0.843948\n",
      " 744.jpg                 1         0.843119    0.843119\n",
      "\n",
      "============================================================\n",
      "Top 10 Least Confident Predictions (Review These):\n",
      "============================================================\n",
      "filename  prediction_class  prediction_prob  confidence\n",
      " 816.jpg                 0         0.491933    0.508067\n",
      " 794.jpg                 1         0.508033    0.508033\n",
      " 619.jpg                 0         0.492507    0.507493\n",
      "  66.jpg                 0         0.493777    0.506223\n",
      " 580.jpg                 0         0.494928    0.505072\n",
      " 517.jpg                 0         0.496822    0.503178\n",
      " 500.jpg                 0         0.498865    0.501135\n",
      "  26.jpg                 0         0.499747    0.500253\n",
      " 618.jpg                 1         0.500233    0.500233\n",
      " 802.jpg                 0         0.499990    0.500010\n",
      "\n",
      "============================================================\n",
      "âœ“ Results saved to convnext_predictions.csv\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "class ConvNeXtClassifier(nn.Module):\n",
    "    def __init__(self, model_name='convnext_tiny.fb_in22k_ft_in1k', pretrained=False, dropout=0.3):\n",
    "        super(ConvNeXtClassifier, self).__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, num_classes=0)\n",
    "        in_features = self.model.num_features\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "            nn.BatchNorm1d(in_features),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(dropout / 2),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.model(x)\n",
    "        return self.head(features).squeeze()\n",
    "\n",
    "\n",
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, img_path\n",
    "\n",
    "\n",
    "def get_tta_transforms(img_size=256):\n",
    "    \"\"\"Get multiple augmented versions of the same image\"\"\"\n",
    "    tta_transforms = [\n",
    "        \n",
    "        transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        \n",
    "        transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.RandomHorizontalFlip(p=1.0),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        \n",
    "        transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.RandomRotation(degrees=5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    ]\n",
    "    return tta_transforms\n",
    "\n",
    "\n",
    "def predict_single_model(model, loader, device, use_tta=False, tta_transforms=None):\n",
    "    \"\"\"Make predictions using a single model\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    image_paths = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, paths in tqdm(loader, desc='Predicting'):\n",
    "            if use_tta and tta_transforms:\n",
    "                \n",
    "                batch_preds = []\n",
    "                for tta_transform in tta_transforms:\n",
    "                    tta_images = torch.stack([\n",
    "                        tta_transform(Image.open(path).convert('RGB')) \n",
    "                        for path in paths\n",
    "                    ]).to(device)\n",
    "                    \n",
    "                    outputs = model(tta_images)\n",
    "                    preds = torch.sigmoid(outputs).cpu().numpy()\n",
    "                    if preds.ndim == 0:\n",
    "                        preds = np.array([float(preds)])\n",
    "                    batch_preds.append(preds)\n",
    "                \n",
    "                \n",
    "                preds = np.mean(batch_preds, axis=0)\n",
    "            else:\n",
    "                images = images.to(device)\n",
    "                outputs = model(images)\n",
    "                preds = torch.sigmoid(outputs).cpu().numpy()\n",
    "                \n",
    "                if preds.ndim == 0:\n",
    "                    preds = np.array([float(preds)])\n",
    "            \n",
    "            predictions.extend(preds.tolist() if isinstance(preds, np.ndarray) else [preds])\n",
    "            image_paths.extend(paths)\n",
    "    \n",
    "    return np.array(predictions), image_paths\n",
    "\n",
    "\n",
    "def ensemble_predict(weights_dir, image_paths, img_size=256, batch_size=32, \n",
    "                     num_folds=5, use_tta=False, model_name='convnext_tiny.fb_in22k_ft_in1k'):\n",
    "    \"\"\"\n",
    "    Make predictions using ensemble of all fold models\n",
    "    \n",
    "    Args:\n",
    "        weights_dir: Directory containing model weights\n",
    "        image_paths: List of image paths to predict\n",
    "        img_size: Input image size\n",
    "        batch_size: Batch size for inference\n",
    "        num_folds: Number of CV folds\n",
    "        use_tta: Whether to use test-time augmentation\n",
    "        model_name: ConvNeXt model variant\n",
    "    \n",
    "    Returns:\n",
    "        ensemble_preds: Averaged predictions from all folds\n",
    "        fold_preds: Individual predictions from each fold\n",
    "        image_paths: List of image paths\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    tta_transforms = get_tta_transforms(img_size) if use_tta else None\n",
    "    \n",
    "    \n",
    "    dataset = InferenceDataset(image_paths, transform if not use_tta else None)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, \n",
    "                       num_workers=2, pin_memory=True)\n",
    "    \n",
    "    all_predictions = []\n",
    "    fold_info = []\n",
    "    \n",
    "    \n",
    "    for fold in range(num_folds):\n",
    "        weight_path = os.path.join(weights_dir, f'convnext_fold{fold+1}_best.pth')\n",
    "        \n",
    "        if not os.path.exists(weight_path):\n",
    "            print(f\"âš  Warning: {weight_path} not found, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Loading Fold {fold + 1} weights...\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        \n",
    "        model = ConvNeXtClassifier(model_name=model_name, pretrained=False).to(device)\n",
    "        checkpoint = torch.load(    weight_path,\n",
    "    map_location=device,\n",
    "    weights_only=False   \n",
    ")\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        \n",
    "        print(f\"âœ“ Model loaded successfully\")\n",
    "        print(f\"  - Epoch: {checkpoint.get('epoch', 'N/A')}\")\n",
    "        print(f\"  - Val AUC: {checkpoint.get('val_auc', 'N/A'):.4f}\")\n",
    "        print(f\"  - Val Acc: {checkpoint.get('val_acc', 'N/A'):.4f}\")\n",
    "        print(f\"  - Val F1: {checkpoint.get('val_f1', 'N/A'):.4f}\")\n",
    "        \n",
    "        \n",
    "        predictions, paths = predict_single_model(\n",
    "            model, loader, device, \n",
    "            use_tta=use_tta, \n",
    "            tta_transforms=tta_transforms\n",
    "        )\n",
    "        all_predictions.append(predictions)\n",
    "        fold_info.append({\n",
    "            'fold': fold + 1,\n",
    "            'val_auc': checkpoint.get('val_auc', 0),\n",
    "            'val_acc': checkpoint.get('val_acc', 0),\n",
    "        })\n",
    "        \n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    if not all_predictions:\n",
    "        raise ValueError(\"No model weights found! Check weights_dir path.\")\n",
    "    \n",
    "    \n",
    "    ensemble_preds = np.mean(all_predictions, axis=0)\n",
    "    \n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ENSEMBLE SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Models used: {len(all_predictions)}/{num_folds}\")\n",
    "    for info in fold_info:\n",
    "        print(f\"  Fold {info['fold']}: AUC={info['val_auc']:.4f}, Acc={info['val_acc']:.4f}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    return ensemble_preds, all_predictions, paths\n",
    "\n",
    "\n",
    "def predict_best_model(weights_dir, image_paths, img_size=256, batch_size=32, \n",
    "                      use_tta=False, model_name='convnext_tiny.fb_in22k_ft_in1k'):\n",
    "    \"\"\"\n",
    "    Make predictions using the single best performing fold model\n",
    "    \n",
    "    Args:\n",
    "        weights_dir: Directory containing model weights\n",
    "        image_paths: List of image paths to predict\n",
    "        img_size: Input image size\n",
    "        batch_size: Batch size for inference\n",
    "        use_tta: Whether to use test-time augmentation\n",
    "        model_name: ConvNeXt model variant\n",
    "    \n",
    "    Returns:\n",
    "        predictions: Model predictions\n",
    "        image_paths: List of image paths\n",
    "        best_fold: Best fold number\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    weight_files = glob.glob(os.path.join(weights_dir, 'convnext_fold*_best.pth'))\n",
    "    \n",
    "    if not weight_files:\n",
    "        raise ValueError(f\"No model weights found in {weights_dir}\")\n",
    "    \n",
    "    best_auc = 0\n",
    "    best_weight_path = None\n",
    "    best_fold = None\n",
    "    \n",
    "    for weight_path in weight_files:\n",
    "        checkpoint = torch.load(weight_path, map_location='cpu',\n",
    "    weights_only=False )\n",
    "        auc = checkpoint.get('val_auc', 0)\n",
    "        if auc > best_auc:\n",
    "            best_auc = auc\n",
    "            best_weight_path = weight_path\n",
    "            fold_num = os.path.basename(weight_path).split('fold')[1].split('_')[0]\n",
    "            best_fold = int(fold_num)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Using Best Model: Fold {best_fold}\")\n",
    "    print(f\"Validation AUC: {best_auc:.4f}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    tta_transforms = get_tta_transforms(img_size) if use_tta else None\n",
    "    \n",
    "    \n",
    "    dataset = InferenceDataset(image_paths, transform if not use_tta else None)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, \n",
    "                       num_workers=2, pin_memory=True)\n",
    "    \n",
    "    \n",
    "    model = ConvNeXtClassifier(model_name=model_name, pretrained=False).to(device)\n",
    "    checkpoint = torch.load(best_weight_path, map_location=device,\n",
    "    weights_only=False )\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    \n",
    "    predictions, paths = predict_single_model(\n",
    "        model, loader, device,\n",
    "        use_tta=use_tta,\n",
    "        tta_transforms=tta_transforms\n",
    "    )\n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return predictions, paths, best_fold\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Example usage of inference functions\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    IMAGE_DIR = '/kaggle/input/notebooks/kagglertw/shemagh-right-placev2/images'\n",
    "    WEIGHTS_DIR = '/kaggle/input/notebooks/kagglertw/shemagh-right-place-binaryv2/weights_convnext/'\n",
    "    OUTPUT_FILE = 'convnext_predictions.csv'\n",
    "    \n",
    "    \n",
    "    image_extensions = ('*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG')\n",
    "    image_paths = []\n",
    "    for ext in image_extensions:\n",
    "        image_paths.extend(glob.glob(os.path.join(IMAGE_DIR, ext)))\n",
    "    \n",
    "    if not image_paths:\n",
    "        print(f\"âš  No images found in {IMAGE_DIR}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(image_paths)} images\")\n",
    "    \n",
    "    \n",
    "    print(\"\\nInference Options:\")\n",
    "    print(\"1. Ensemble (All folds) - Most accurate\")\n",
    "    print(\"2. Best single model - Faster\")\n",
    "    print(\"3. Ensemble with TTA - Highest accuracy (slower)\")\n",
    "    \n",
    "    choice = \"1\"\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        \n",
    "        print(\"\\nðŸš€ Running Ensemble Prediction (All Folds)...\")\n",
    "        ensemble_preds, fold_preds, paths = ensemble_predict(\n",
    "            WEIGHTS_DIR, \n",
    "            image_paths,\n",
    "            img_size=256,\n",
    "            batch_size=32,\n",
    "            num_folds=5,\n",
    "            use_tta=False\n",
    "        )\n",
    "        \n",
    "        \n",
    "        results_df = pd.DataFrame({\n",
    "            'filename': [os.path.basename(p) for p in paths],\n",
    "            'image_path': paths,\n",
    "            'prediction_prob': ensemble_preds,\n",
    "            'prediction_class': (ensemble_preds >= 0.5).astype(int),\n",
    "            'confidence': np.maximum(ensemble_preds, 1 - ensemble_preds)\n",
    "        })\n",
    "        \n",
    "        \n",
    "        for i, preds in enumerate(fold_preds):\n",
    "            results_df[f'fold_{i+1}_prob'] = preds\n",
    "        \n",
    "        \n",
    "        results_df['prediction_variance'] = np.var(fold_preds, axis=0)\n",
    "        \n",
    "    elif choice == \"2\":\n",
    "        \n",
    "        print(\"\\nðŸš€ Running Best Single Model Prediction...\")\n",
    "        predictions, paths, best_fold = predict_best_model(\n",
    "            WEIGHTS_DIR,\n",
    "            image_paths,\n",
    "            img_size=256,\n",
    "            batch_size=32,\n",
    "            use_tta=False\n",
    "        )\n",
    "        \n",
    "        results_df = pd.DataFrame({\n",
    "            'filename': [os.path.basename(p) for p in paths],\n",
    "            'image_path': paths,\n",
    "            'prediction_prob': predictions,\n",
    "            'prediction_class': (predictions >= 0.5).astype(int),\n",
    "            'confidence': np.maximum(predictions, 1 - predictions),\n",
    "            'model_fold': best_fold\n",
    "        })\n",
    "        \n",
    "    else:  \n",
    "        \n",
    "        print(\"\\nðŸš€ Running Ensemble Prediction with TTA...\")\n",
    "        print(\"âš  This will be slower but more accurate\")\n",
    "        ensemble_preds, fold_preds, paths = ensemble_predict(\n",
    "            WEIGHTS_DIR,\n",
    "            image_paths,\n",
    "            img_size=256,\n",
    "            batch_size=16,  \n",
    "            num_folds=5,\n",
    "            use_tta=True\n",
    "        )\n",
    "        \n",
    "        results_df = pd.DataFrame({\n",
    "            'filename': [os.path.basename(p) for p in paths],\n",
    "            'image_path': paths,\n",
    "            'prediction_prob': ensemble_preds,\n",
    "            'prediction_class': (ensemble_preds >= 0.5).astype(int),\n",
    "            'confidence': np.maximum(ensemble_preds, 1 - ensemble_preds)\n",
    "        })\n",
    "        \n",
    "        for i, preds in enumerate(fold_preds):\n",
    "            results_df[f'fold_{i+1}_prob'] = preds\n",
    "        results_df['prediction_variance'] = np.var(fold_preds, axis=0)\n",
    "    \n",
    "    \n",
    "    results_df = results_df.sort_values('confidence', ascending=False)\n",
    "    \n",
    "    \n",
    "    results_df.to_csv(OUTPUT_FILE, index=False)\n",
    "    \n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"PREDICTION SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total images: {len(results_df)}\")\n",
    "    print(f\"\\nClass distribution:\")\n",
    "    print(results_df['prediction_class'].value_counts().sort_index())\n",
    "    print(f\"\\nConfidence statistics:\")\n",
    "    print(results_df['confidence'].describe())\n",
    "    \n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Top 10 Most Confident Predictions:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(results_df[['filename', 'prediction_class', 'prediction_prob', 'confidence']].head(10).to_string(index=False))\n",
    "    \n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Top 10 Least Confident Predictions (Review These):\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(results_df[['filename', 'prediction_class', 'prediction_prob', 'confidence']].tail(10).to_string(index=False))\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"âœ“ Results saved to {OUTPUT_FILE}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 9485667,
     "sourceId": 14831476,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 297939165,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 297940817,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 63.120819,
   "end_time": "2026-02-16T02:18:03.575005",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-16T02:17:00.454186",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
