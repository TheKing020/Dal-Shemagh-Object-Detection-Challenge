{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "execution_failed": "2026-02-17T16:51:05.139Z",
     "iopub.execute_input": "2026-02-17T15:35:16.822320Z",
     "iopub.status.busy": "2026-02-17T15:35:16.821639Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "\n",
      "── Found 842 images ──\n",
      "\n",
      "── Extracting features for all images ──\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extraction:  61%|██████    | 511/842 [02:01<01:18,  4.20it/s]"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Image Similarity v3 — Pairwise Multi-Descriptor Fusion\n",
    "========================================================\n",
    "Compares EVERY image with EVERY other image in the test folder.\n",
    "\n",
    "Three complementary descriptors computed for each pair:\n",
    "  1. Deep CNN features  — EfficientNet-B4 at 480px\n",
    "  2. Color histogram    — HSV histogram\n",
    "  3. Texture (LBP)      — Local Binary Patterns\n",
    "\n",
    "Output DataFrame columns:\n",
    "  image1 | image2 | sim_deep | sim_color | sim_texture | sim_fused\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "TEST_DIR   = \"/kaggle/input/datasets/kagglertw/dal-shemagh/dal-shemagh-detection-challenge/images/test\"\n",
    "OUTPUT_CSV = \"pairwise_similarity_results.csv\"\n",
    "\n",
    "\n",
    "W_DEEP    = 0.50\n",
    "W_COLOR   = 0.25\n",
    "W_TEXTURE = 0.25\n",
    "\n",
    "\n",
    "CNN_SIZE  = 480\n",
    "\n",
    "\n",
    "LBP_RADIUS   = 3\n",
    "LBP_N_POINTS = 8 * LBP_RADIUS\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "backbone = models.efficientnet_b4(weights=models.EfficientNet_B4_Weights.IMAGENET1K_V1)\n",
    "backbone.classifier = torch.nn.Identity()\n",
    "backbone = backbone.to(device).eval()\n",
    "\n",
    "cnn_transform = T.Compose([\n",
    "    T.Resize((CNN_SIZE, CNN_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def deep_feat(img_path: str) -> np.ndarray | None:\n",
    "    \"\"\"EfficientNet-B4 → 1792-D feature vector.\"\"\"\n",
    "    try:\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        t   = cnn_transform(img).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            f = backbone(t)\n",
    "        return f.squeeze().cpu().numpy()\n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠ deep_feat failed for {img_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def color_hist(img_path: str, bins=(16, 8, 8)) -> np.ndarray | None:\n",
    "    \"\"\"HSV histogram: H=16 bins, S=8, V=8 → 1024-D normalised vector.\"\"\"\n",
    "    try:\n",
    "        bgr = cv2.imread(img_path)\n",
    "        if bgr is None:\n",
    "            raise IOError(\"cv2.imread returned None\")\n",
    "        hsv = cv2.cvtColor(bgr, cv2.COLOR_BGR2HSV)\n",
    "        hist = cv2.calcHist(\n",
    "            [hsv], [0, 1, 2], None,\n",
    "            [bins[0], bins[1], bins[2]],\n",
    "            [0, 180, 0, 256, 0, 256]\n",
    "        )\n",
    "        hist = hist.flatten().astype(np.float32)\n",
    "        norm = np.linalg.norm(hist)\n",
    "        return hist / norm if norm > 0 else hist\n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠ color_hist failed for {img_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def texture_lbp(img_path: str) -> np.ndarray | None:\n",
    "    \"\"\"LBP on grayscale image → normalised histogram.\"\"\"\n",
    "    try:\n",
    "        bgr  = cv2.imread(img_path)\n",
    "        if bgr is None:\n",
    "            raise IOError(\"cv2.imread returned None\")\n",
    "        gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        h, w   = gray.shape\n",
    "        n_bins = LBP_N_POINTS + 2\n",
    "        hists  = []\n",
    "\n",
    "        \n",
    "        for row in range(3):\n",
    "            for col in range(3):\n",
    "                patch = gray[row*h//3:(row+1)*h//3,\n",
    "                             col*w//3:(col+1)*w//3]\n",
    "                lbp   = local_binary_pattern(patch, LBP_N_POINTS,\n",
    "                                             LBP_RADIUS, method=\"uniform\")\n",
    "                hist, _ = np.histogram(lbp.ravel(), bins=n_bins,\n",
    "                                       range=(0, n_bins), density=True)\n",
    "                hists.append(hist)\n",
    "\n",
    "        feat = np.concatenate(hists).astype(np.float32)\n",
    "        norm = np.linalg.norm(feat)\n",
    "        return feat / norm if norm > 0 else feat\n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠ texture_lbp failed for {img_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "all_images = sorted([\n",
    "    f for f in os.listdir(TEST_DIR)\n",
    "    if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "])\n",
    "print(f\"\\n── Found {len(all_images)} images ──\")\n",
    "\n",
    "\n",
    "features_cache = {}\n",
    "\n",
    "print(\"\\n── Extracting features for all images ──\")\n",
    "for fname in tqdm(all_images, desc=\"Feature extraction\"):\n",
    "    fpath = os.path.join(TEST_DIR, fname)\n",
    "    \n",
    "    d = deep_feat(fpath)\n",
    "    c = color_hist(fpath)\n",
    "    t = texture_lbp(fpath)\n",
    "    \n",
    "    if d is not None and c is not None and t is not None:\n",
    "        features_cache[fname] = {\n",
    "            'deep': d,\n",
    "            'color': c,\n",
    "            'texture': t\n",
    "        }\n",
    "    else:\n",
    "        print(f\"  ⚠ Skipping {fname} due to feature extraction failure\")\n",
    "\n",
    "valid_images = list(features_cache.keys())\n",
    "print(f\"\\n✓ Successfully extracted features for {len(valid_images)} images\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "total_pairs = len(valid_images) * (len(valid_images) - 1) // 2\n",
    "print(f\"\\n── Computing {total_pairs:,} pairwise similarities ──\")\n",
    "\n",
    "records = []\n",
    "for img1, img2 in tqdm(combinations(valid_images, 2), \n",
    "                       total=total_pairs, \n",
    "                       desc=\"Pairwise comparison\"):\n",
    "    \n",
    "    feat1 = features_cache[img1]\n",
    "    feat2 = features_cache[img2]\n",
    "    \n",
    "    \n",
    "    sim_d = float(cosine_similarity(\n",
    "        feat1['deep'].reshape(1, -1), \n",
    "        feat2['deep'].reshape(1, -1)\n",
    "    )[0, 0])\n",
    "    \n",
    "    sim_c = float(cosine_similarity(\n",
    "        feat1['color'].reshape(1, -1), \n",
    "        feat2['color'].reshape(1, -1)\n",
    "    )[0, 0])\n",
    "    \n",
    "    sim_t = float(cosine_similarity(\n",
    "        feat1['texture'].reshape(1, -1), \n",
    "        feat2['texture'].reshape(1, -1)\n",
    "    )[0, 0])\n",
    "    \n",
    "    \n",
    "    sim_f = W_DEEP * sim_d + W_COLOR * sim_c + W_TEXTURE * sim_t\n",
    "    \n",
    "    records.append({\n",
    "        \"image1\"      : img1,\n",
    "        \"image2\"      : img2,\n",
    "        \"sim_deep\"    : round(sim_d, 6),\n",
    "        \"sim_color\"   : round(sim_c, 6),\n",
    "        \"sim_texture\" : round(sim_t, 6),\n",
    "        \"sim_fused\"   : round(sim_f, 6),\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "df = df.sort_values(\"sim_fused\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n── Top 10 most similar pairs ──\")\n",
    "print(df.head(10).to_string(index=False))\n",
    "print(f\"\\nTotal pairs: {len(df):,}\")\n",
    "print(f\"Columns    : {list(df.columns)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"\\n✅  Saved → '{OUTPUT_CSV}'\")\n",
    "\n",
    "\n",
    "print(\"\\n── Statistics ──\")\n",
    "print(f\"Mean fused similarity: {df['sim_fused'].mean():.4f}\")\n",
    "print(f\"Max fused similarity:  {df['sim_fused'].max():.4f}\")\n",
    "print(f\"Min fused similarity:  {df['sim_fused'].min():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 9485667,
     "sourceId": 14831476,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
