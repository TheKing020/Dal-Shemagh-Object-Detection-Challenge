{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54d5125",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-02-15T22:59:18.959811Z",
     "iopub.status.busy": "2026-02-15T22:59:18.959498Z",
     "iopub.status.idle": "2026-02-15T22:59:36.119701Z",
     "shell.execute_reply": "2026-02-15T22:59:36.118611Z"
    },
    "papermill": {
     "duration": 17.166463,
     "end_time": "2026-02-15T22:59:36.121522",
     "exception": false,
     "start_time": "2026-02-15T22:59:18.955059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "CONFIG = {\n",
    "    'image_dir': '/kaggle/input/notebooks/kagglertw/shemagh-right-place/images',\n",
    "    'csv_path': '/kaggle/input/notebooks/kagglertw/shemagh-right-place/train_df.csv',\n",
    "    'img_size': 240,\n",
    "    'batch_size': 32,\n",
    "    'num_epochs': 25,  \n",
    "    'learning_rate': 5e-5,  \n",
    "    'weight_decay': 1e-4,  \n",
    "    'num_folds': 5,\n",
    "    'seed': 42,\n",
    "    'num_workers': 2,\n",
    "    'model_name': 'efficientnet_b0',\n",
    "    'save_dir': './weights_improved',\n",
    "    'early_stopping_patience': 5,  \n",
    "    'use_class_weights': True,  \n",
    "    'dropout': 0.4,  \n",
    "}\n",
    "\n",
    "os.makedirs(CONFIG['save_dir'], exist_ok=True)\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(CONFIG['seed'])\n",
    "\n",
    "\n",
    "class BinaryImageDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.df.loc[idx, 'filename']\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = self.df.loc[idx, 'right_place']\n",
    "        return image, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((CONFIG['img_size'], CONFIG['img_size'])),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.2),  \n",
    "    transforms.RandomRotation(20),  \n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  \n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.15),  \n",
    "    transforms.RandomGrayscale(p=0.1),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                       std=[0.229, 0.224, 0.225]),\n",
    "    transforms.RandomErasing(p=0.3, scale=(0.02, 0.15)),  \n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((CONFIG['img_size'], CONFIG['img_size'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                       std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "class EfficientNetB1Classifier(nn.Module):\n",
    "    def __init__(self, pretrained=True, dropout=0.4):\n",
    "        super(EfficientNetB1Classifier, self).__init__()\n",
    "        self.model = timm.create_model('efficientnet_b0', pretrained=pretrained)\n",
    "        in_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(in_features, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.001, mode='max'):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        \n",
    "    def __call__(self, score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif self.mode == 'max':\n",
    "            if score < self.best_score + self.min_delta:\n",
    "                self.counter += 1\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.counter = 0\n",
    "        elif self.mode == 'min':\n",
    "            if score > self.best_score - self.min_delta:\n",
    "                self.counter += 1\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.counter = 0\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    \n",
    "    pbar = tqdm(loader, desc='Training')\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        preds = torch.sigmoid(outputs).detach().cpu().numpy()\n",
    "        predictions.extend(preds)\n",
    "        targets.extend(labels.cpu().numpy())\n",
    "        \n",
    "        pbar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    return epoch_loss, np.array(predictions), np.array(targets)\n",
    "\n",
    "def validate_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc='Validation')\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            preds = torch.sigmoid(outputs).cpu().numpy()\n",
    "            predictions.extend(preds)\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "            \n",
    "            pbar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    return epoch_loss, np.array(predictions), np.array(targets)\n",
    "\n",
    "def calculate_metrics(predictions, targets, threshold=0.5):\n",
    "    pred_binary = (predictions >= threshold).astype(int)\n",
    "    accuracy = accuracy_score(targets, pred_binary)\n",
    "    auc = roc_auc_score(targets, predictions)\n",
    "    f1 = f1_score(targets, pred_binary)\n",
    "    return accuracy, auc, f1\n",
    "\n",
    "def train_fold(fold, train_df, val_df, config):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training Fold {fold + 1}/{config['num_folds']}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    \n",
    "    train_dataset = BinaryImageDataset(train_df, config['image_dir'], train_transform)\n",
    "    val_dataset = BinaryImageDataset(val_df, config['image_dir'], val_transform)\n",
    "    \n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], \n",
    "                            shuffle=True, num_workers=config['num_workers'])\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], \n",
    "                          shuffle=False, num_workers=config['num_workers'])\n",
    "    \n",
    "    \n",
    "    model = EfficientNetB1Classifier(\n",
    "        pretrained=True, \n",
    "        dropout=config['dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    \n",
    "    if config['use_class_weights']:\n",
    "        pos_count = (train_df['right_place'] == 1).sum()\n",
    "        neg_count = (train_df['right_place'] == 0).sum()\n",
    "        pos_weight = torch.tensor([neg_count / pos_count]).to(device)\n",
    "        criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "        print(f\"Using weighted loss - Pos weight: {pos_weight.item():.2f}\")\n",
    "    else:\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    \n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(), \n",
    "        lr=config['learning_rate'],\n",
    "        weight_decay=config['weight_decay']\n",
    "    )\n",
    "    \n",
    "    \n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer, T_0=5, T_mult=1, eta_min=1e-7\n",
    "    )\n",
    "    \n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "        patience=config['early_stopping_patience'],\n",
    "        mode='max'\n",
    "    )\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_auc = 0.0\n",
    "    \n",
    "    \n",
    "    for epoch in range(config['num_epochs']):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{config['num_epochs']} | LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "        \n",
    "        \n",
    "        train_loss, train_preds, train_targets = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, device\n",
    "        )\n",
    "        train_acc, train_auc, train_f1 = calculate_metrics(train_preds, train_targets)\n",
    "        \n",
    "        \n",
    "        val_loss, val_preds, val_targets = validate_epoch(\n",
    "            model, val_loader, criterion, device\n",
    "        )\n",
    "        val_acc, val_auc, val_f1 = calculate_metrics(val_preds, val_targets)\n",
    "        \n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | AUC: {train_auc:.4f} | F1: {train_f1:.4f}\")\n",
    "        print(f\"Val   Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | AUC: {val_auc:.4f} | F1: {val_f1:.4f}\")\n",
    "        \n",
    "        \n",
    "        if val_auc > best_auc:\n",
    "            best_auc = val_auc\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "                'val_auc': val_auc,\n",
    "                'val_acc': val_acc,\n",
    "                'config': config,\n",
    "            }, os.path.join(config['save_dir'], f'effnet_b0_fold{fold+1}_best.pth'))\n",
    "            print(f\"✓ Saved best model (AUC: {best_auc:.4f})\")\n",
    "        \n",
    "        \n",
    "        early_stopping(val_auc)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "            break\n",
    "    \n",
    "    return best_val_loss, best_auc\n",
    "\n",
    "def main():\n",
    "    print(\"Loading data...\")\n",
    "    df = pd.read_csv(CONFIG['csv_path'])\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Class distribution:\\n{df['right_place'].value_counts()}\")\n",
    "    print(f\"Class imbalance ratio: {(df['right_place']==0).sum() / (df['right_place']==1).sum():.2f}:1\")\n",
    "    \n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=CONFIG['num_folds'], shuffle=True, random_state=CONFIG['seed'])\n",
    "    \n",
    "    \n",
    "    fold_results = []\n",
    "    \n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['right_place'])):\n",
    "        train_df = df.iloc[train_idx]\n",
    "        val_df = df.iloc[val_idx]\n",
    "        \n",
    "        print(f\"\\nFold {fold + 1} - Train: {len(train_df)}, Val: {len(val_df)}\")\n",
    "        print(f\"Train class distribution:\\n{train_df['right_place'].value_counts()}\")\n",
    "        print(f\"Val class distribution:\\n{val_df['right_place'].value_counts()}\")\n",
    "        \n",
    "        val_loss, val_auc = train_fold(fold, train_df, val_df, CONFIG)\n",
    "        fold_results.append({'fold': fold + 1, 'val_loss': val_loss, 'val_auc': val_auc})\n",
    "    \n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"Cross-Validation Summary\")\n",
    "    print(f\"{'='*50}\")\n",
    "    results_df = pd.DataFrame(fold_results)\n",
    "    print(results_df)\n",
    "    print(f\"\\nMean AUC: {results_df['val_auc'].mean():.4f} ± {results_df['val_auc'].std():.4f}\")\n",
    "    print(f\"Mean Loss: {results_df['val_loss'].mean():.4f} ± {results_df['val_loss'].std():.4f}\")\n",
    "    \n",
    "    \n",
    "    results_df.to_csv(os.path.join(CONFIG['save_dir'], 'cv_results.csv'), index=False)\n",
    "    print(f\"\\n✓ Results saved to {CONFIG['save_dir']}/cv_results.csv\")\n",
    "    print(f\"✓ Model weights saved in {CONFIG['save_dir']}/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54b3272",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T22:59:36.126471Z",
     "iopub.status.busy": "2026-02-15T22:59:36.126223Z",
     "iopub.status.idle": "2026-02-15T23:00:08.569645Z",
     "shell.execute_reply": "2026-02-15T23:00:08.568068Z"
    },
    "papermill": {
     "duration": 32.448082,
     "end_time": "2026-02-15T23:00:08.571416",
     "exception": false,
     "start_time": "2026-02-15T22:59:36.123334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Found 842 images\n",
      "\n",
      "==================================================\n",
      "Running Ensemble Prediction\n",
      "==================================================\n",
      "\n",
      "Loading fold 1 weights...\n",
      "Fold 1 - Val AUC: 0.8206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 27/27 [00:10<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading fold 2 weights...\n",
      "Fold 2 - Val AUC: 0.8363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 27/27 [00:04<00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading fold 3 weights...\n",
      "Fold 3 - Val AUC: 0.8844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 27/27 [00:04<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading fold 4 weights...\n",
      "Fold 4 - Val AUC: 0.8487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 27/27 [00:04<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading fold 5 weights...\n",
      "Fold 5 - Val AUC: 0.7672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 27/27 [00:04<00:00,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Predictions saved to predictions.csv\n",
      "\n",
      "Sample predictions:\n",
      "  filename  prediction_prob  prediction_class  fold_1_prob  fold_2_prob  \\\n",
      "0  623.jpg         0.750885                 1     0.830798     0.756628   \n",
      "1  764.jpg         0.248612                 0     0.159409     0.349164   \n",
      "2  771.jpg         0.519455                 1     0.554730     0.541493   \n",
      "3  208.jpg         0.395363                 0     0.377498     0.405647   \n",
      "4  820.jpg         0.552467                 1     0.609143     0.526818   \n",
      "5  473.jpg         0.214795                 0     0.200305     0.152140   \n",
      "6  333.jpg         0.547931                 1     0.567810     0.563017   \n",
      "7  537.jpg         0.212417                 0     0.120150     0.261906   \n",
      "8   45.jpg         0.438628                 0     0.459107     0.479885   \n",
      "9  369.jpg         0.220761                 0     0.095426     0.311770   \n",
      "\n",
      "   fold_3_prob  fold_4_prob  fold_5_prob  \n",
      "0     0.724820     0.663660     0.778519  \n",
      "1     0.259275     0.348190     0.127023  \n",
      "2     0.461676     0.549737     0.489635  \n",
      "3     0.494537     0.386977     0.312156  \n",
      "4     0.509326     0.564013     0.553038  \n",
      "5     0.265736     0.348897     0.106899  \n",
      "6     0.466322     0.602041     0.540465  \n",
      "7     0.220413     0.309361     0.150254  \n",
      "8     0.582219     0.460493     0.211434  \n",
      "9     0.250383     0.342958     0.103267  \n",
      "\n",
      "Prediction distribution:\n",
      "prediction_class\n",
      "0    595\n",
      "1    247\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "class EfficientNetB1Classifier(nn.Module):\n",
    "    def __init__(self, pretrained=False):\n",
    "        super(EfficientNetB1Classifier, self).__init__()\n",
    "        self.model = timm.create_model('efficientnet_b0', pretrained=pretrained)\n",
    "        in_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(in_features, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image\n",
    "\n",
    "\n",
    "def predict(model, loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images in tqdm(loader, desc='Predicting'):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images).squeeze()\n",
    "            preds = torch.sigmoid(outputs).cpu().numpy()\n",
    "            \n",
    "            if preds.ndim == 0:  \n",
    "                predictions.append(float(preds))\n",
    "            else:\n",
    "                predictions.extend(preds.tolist())\n",
    "    \n",
    "    return np.array(predictions)\n",
    "\n",
    "\n",
    "def ensemble_predict(weights_dir, image_paths, img_size=240, batch_size=32, num_folds=5):\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    dataset = InferenceDataset(image_paths, transform)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    \n",
    "    all_predictions = []\n",
    "    \n",
    "    \n",
    "    for fold in range(num_folds):\n",
    "        weight_path = os.path.join(weights_dir, f'effnet_b0_fold{fold+1}_best.pth')\n",
    "        \n",
    "        if not os.path.exists(weight_path):\n",
    "            print(f\"Warning: {weight_path} not found, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nLoading fold {fold + 1} weights...\")\n",
    "        model = EfficientNetB1Classifier(pretrained=False).to(device)\n",
    "        checkpoint = torch.load(\n",
    "    weight_path,\n",
    "    map_location=device,\n",
    "    weights_only=False   \n",
    ")\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        print(f\"Fold {fold + 1} - Val AUC: {checkpoint.get('val_auc', 'N/A'):.4f}\")\n",
    "        \n",
    "        predictions = predict(model, loader, device)\n",
    "        all_predictions.append(predictions)\n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    \n",
    "    ensemble_preds = np.mean(all_predictions, axis=0)\n",
    "    \n",
    "    return ensemble_preds, all_predictions\n",
    "\n",
    "\n",
    "def single_model_predict(weight_path, image_paths, img_size=240, batch_size=32):\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    dataset = InferenceDataset(image_paths, transform)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    \n",
    "    \n",
    "    print(f\"Loading model from {weight_path}...\")\n",
    "    model = EfficientNetB1Classifier(pretrained=False).to(device)\n",
    "    checkpoint = torch.load(\n",
    "    weight_path,\n",
    "    map_location=device,\n",
    "    weights_only=False   \n",
    ")\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    print(f\"Model Val AUC: {checkpoint.get('val_auc', 'N/A'):.4f}\")\n",
    "    \n",
    "    \n",
    "    predictions = predict(model, loader, device)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    image_dir = '/kaggle/input/datasets/kagglertw/dal-shemagh/dal-shemagh-detection-challenge/images/test'\n",
    "    weights_dir = '/kaggle/input/notebooks/kagglertw/shemagh-right-place-binary/weights_improved/'\n",
    "    \n",
    "    \n",
    "    test_csv = 'test.csv'  \n",
    "    \n",
    "    \n",
    "    if os.path.exists(test_csv):\n",
    "        test_df = pd.read_csv(test_csv)\n",
    "        image_paths = [os.path.join(image_dir, fname) for fname in test_df['filename']]\n",
    "    else:\n",
    "        \n",
    "        image_paths = [os.path.join(image_dir, f) for f in os.listdir(image_dir) \n",
    "                      if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    print(f\"Found {len(image_paths)} images\")\n",
    "    \n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Running Ensemble Prediction\")\n",
    "    print(\"=\"*50)\n",
    "    ensemble_preds, fold_preds = ensemble_predict(weights_dir, image_paths, num_folds=5)\n",
    "    \n",
    "    \n",
    "    results_df = pd.DataFrame({\n",
    "        'filename': [os.path.basename(p) for p in image_paths],\n",
    "        'prediction_prob': ensemble_preds,\n",
    "        'prediction_class': (ensemble_preds >= 0.5).astype(int)\n",
    "    })\n",
    "    \n",
    "    \n",
    "    for i, preds in enumerate(fold_preds):\n",
    "        results_df[f'fold_{i+1}_prob'] = preds\n",
    "    \n",
    "    \n",
    "    results_df.to_csv('predictions.csv', index=False)\n",
    "    print(f\"\\n✓ Predictions saved to predictions.csv\")\n",
    "    print(f\"\\nSample predictions:\")\n",
    "    print(results_df.head(10))\n",
    "    \n",
    "    print(f\"\\nPrediction distribution:\")\n",
    "    print(results_df['prediction_class'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 9485667,
     "sourceId": 14831476,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 297925277,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 297926955,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 55.143809,
   "end_time": "2026-02-15T23:00:11.370121",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-15T22:59:16.226312",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
